import streamlit as st
import platform
import psutil
import socket
import subprocess
import sys
from datetime import datetime
import os
import pandas as pd

try:
    import tensorflow as tf
except ImportError:
    tf = None

try:
    import torch
except ImportError:
    torch = None

# =============================
# –§–£–ù–ö–¶–ò–Ø: –ü–û–õ–£–ß–ï–ù–ò–ï –ò–ù–§–û–†–ú–ê–¶–ò–ò –û –°–ò–°–¢–ï–ú–ï
# =============================

def get_system_info():
    info = {}

    # –û–±—â–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
    info['hostname'] = socket.gethostname()
    try:
        info['ip'] = socket.gethostbyname(socket.gethostname())
    except:
        info['ip'] = "–ù–µ —É–¥–∞–ª–æ—Å—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å"
    info['datetime'] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
    info['python_version'] = sys.version
    info['python_executable'] = sys.executable
    info['cwd'] = os.getcwd()

    # –û–°
    info['os_system'] = platform.system()
    info['os_version'] = platform.version()
    info['os_platform'] = platform.platform()
    info['architecture'] = f"{platform.machine()} ({platform.architecture()[0]})"
    info['cpu_cores_physical'] = psutil.cpu_count(logical=False)
    info['cpu_cores_logical'] = psutil.cpu_count(logical=True)

    # CPU
    try:
        if info['os_system'] == "Windows":
            cpu_raw = subprocess.check_output("wmic cpu get name", shell=True).decode().strip().split('\n')
            info['cpu_model'] = cpu_raw[1].strip() if len(cpu_raw) > 1 else "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ"
        elif info['os_system'] == "Linux":
            cpu_raw = subprocess.check_output("lscpu | grep 'Model name' | cut -d: -f2", shell=True).decode().strip()
            info['cpu_model'] = cpu_raw or "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ"
        elif info['os_system'] == "Darwin":
            cpu_raw = subprocess.check_output("sysctl -n machdep.cpu.brand_string", shell=True).decode().strip()
            info['cpu_model'] = cpu_raw or "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ"
        else:
            info['cpu_model'] = "–ù–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è"
    except Exception as e:
        info['cpu_model'] = f"–û—à–∏–±–∫–∞: {e}"

    info['cpu_percent'] = psutil.cpu_percent(interval=1)

    # RAM
    mem = psutil.virtual_memory()
    info['ram_total_gb'] = round(mem.total / (1024**3), 2)
    info['ram_used_gb'] = round(mem.used / (1024**3), 2)
    info['ram_available_gb'] = round(mem.available / (1024**3), 2)
    info['ram_percent'] = mem.percent

    # GPU —á–µ—Ä–µ–∑ TensorFlow
    info['tf_gpu'] = []
    if tf:
        info['tf_version'] = tf.__version__
        info['tf_cuda'] = tf.test.is_built_with_cuda()
        gpus = tf.config.list_physical_devices('GPU')
        if gpus:
            for gpu in gpus:
                info['tf_gpu'].append(str(gpu))
    else:
        info['tf_version'] = "‚ùå –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω"

    # GPU —á–µ—Ä–µ–∑ PyTorch
    info['torch_gpu'] = []
    if torch and torch.cuda.is_available():
        info['torch_version'] = torch.__version__
        for i in range(torch.cuda.device_count()):
            info['torch_gpu'].append({
                'name': torch.cuda.get_device_name(i),
                'memory_gb': round(torch.cuda.get_device_properties(i).total_memory / (1024**3), 2)
            })
    else:
        info['torch_version'] = "‚ùå –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –∏–ª–∏ CUDA –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞"

    # nvidia-smi (–µ—Å–ª–∏ –µ—Å—Ç—å)
    info['nvidia_smi'] = []
    try:
        result = subprocess.run(
            ['nvidia-smi', '--query-gpu=name,memory.total,driver_version', '--format=csv,noheader,nounits'],
            capture_output=True, text=True, check=True
        )
        gpus = result.stdout.strip().split('\n')
        for gpu in gpus:
            if gpu:
                name, mem_total, driver = gpu.split(', ')
                info['nvidia_smi'].append({
                    'name': name.strip(),
                    'memory_mb': int(mem_total.strip()),
                    'driver': driver.strip()
                })
    except Exception:
        pass  # nvidia-smi –Ω–µ –¥–æ—Å—Ç—É–ø–µ–Ω ‚Äî –Ω–æ—Ä–º–∞–ª—å–Ω–æ

    # –ë–∏–±–ª–∏–æ—Ç–µ–∫–∏
    libs = {
        "NumPy": "numpy",
        "Pandas": "pandas",
        "OpenCV": "cv2",
        "scikit-learn": "sklearn",
        "Matplotlib": "matplotlib",
        "Seaborn": "seaborn",
        "Streamlit": "streamlit",
        "TensorFlow": "tensorflow",
        "PyTorch": "torch",
    }

    info['libraries'] = {}
    for lib_name, module_name in libs.items():
        try:
            module = __import__(module_name)
            version = getattr(module, '__version__', '–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ')
            info['libraries'][lib_name] = version
        except ImportError:
            info['libraries'][lib_name] = "‚ùå –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω"

    return info

# =============================
# STREAMLIT: –í–´–í–û–î –ò–ù–§–û–†–ú–ê–¶–ò–ò –û –°–ò–°–¢–ï–ú–ï
# =============================

st.markdown("---")
st.header("üñ•Ô∏è –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Å–∏—Å—Ç–µ–º–µ")

with st.spinner("–°–æ–±–∏—Ä–∞–µ–º –¥–∞–Ω–Ω—ã–µ –æ —Å–∏—Å—Ç–µ–º–µ..."):
    sys_info = get_system_info()

# --- –û–±—â–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è ---
st.subheader("üîπ –û–±—â–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è")
st.write(f"**–ò–º—è –∫–æ–º–ø—å—é—Ç–µ—Ä–∞:** `{sys_info['hostname']}`")
st.write(f"**IP-–∞–¥—Ä–µ—Å:** `{sys_info['ip']}`")
st.write(f"**–î–∞—Ç–∞ –∏ –≤—Ä–µ–º—è:** `{sys_info['datetime']}`")
st.write(f"**–†–∞–±–æ—á–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è:** `{sys_info['cwd']}`")

# --- –û–ø–µ—Ä–∞—Ü–∏–æ–Ω–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ ---
st.subheader("üîπ –û–ø–µ—Ä–∞—Ü–∏–æ–Ω–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞")
st.write(f"**–°–∏—Å—Ç–µ–º–∞:** `{sys_info['os_system']}`")
st.write(f"**–í–µ—Ä—Å–∏—è –û–°:** `{sys_info['os_version']}`")
st.write(f"**–ü–ª–∞—Ç—Ñ–æ—Ä–º–∞:** `{sys_info['os_platform']}`")
st.write(f"**–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞:** `{sys_info['architecture']}`")
st.write(f"**CPU —è–¥–µ—Ä:** —Ñ–∏–∑–∏—á–µ—Å–∫–∏—Ö `{sys_info['cpu_cores_physical']}`, –ª–æ–≥–∏—á–µ—Å–∫–∏—Ö `{sys_info['cpu_cores_logical']}`")

# --- –ü—Ä–æ—Ü–µ—Å—Å–æ—Ä ---
st.subheader("üîπ –ü—Ä–æ—Ü–µ—Å—Å–æ—Ä (CPU)")
st.write(f"**–ú–æ–¥–µ–ª—å:** `{sys_info['cpu_model']}`")
st.write(f"**–¢–µ–∫—É—â–∞—è –∑–∞–≥—Ä—É–∑–∫–∞:** `{sys_info['cpu_percent']}%`")

# --- –ü–∞–º—è—Ç—å ---
st.subheader("üîπ –û–ø–µ—Ä–∞—Ç–∏–≤–Ω–∞—è –ø–∞–º—è—Ç—å (RAM)")
st.write(f"**–í—Å–µ–≥–æ:** `{sys_info['ram_total_gb']} GB`")
st.write(f"**–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è:** `{sys_info['ram_used_gb']} GB ({sys_info['ram_percent']}%)`")
st.write(f"**–°–≤–æ–±–æ–¥–Ω–æ:** `{sys_info['ram_available_gb']} GB`")

# --- GPU ---
st.subheader("üîπ –ì—Ä–∞—Ñ–∏—á–µ—Å–∫–∏–π –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä (GPU)")

if tf:
    st.write(f"**TensorFlow –≤–µ—Ä—Å–∏—è:** `{sys_info['tf_version']}`")
    st.write(f"**–°–±–æ—Ä–∫–∞ —Å CUDA:** `{sys_info['tf_cuda']}`")
    if sys_info['tf_gpu']:
        for i, gpu in enumerate(sys_info['tf_gpu']):
            st.write(f"**TF GPU {i}:** `{gpu}`")
    else:
        st.write("‚ùå GPU –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω—ã (TensorFlow)")

if sys_info.get('torch_version') != "‚ùå –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –∏–ª–∏ CUDA –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞":
    st.write(f"**PyTorch –≤–µ—Ä—Å–∏—è:** `{sys_info['torch_version']}`")
    if sys_info['torch_gpu']:
        for i, gpu in enumerate(sys_info['torch_gpu']):
            st.write(f"**Torch GPU {i}:** `{gpu['name']}` ‚Äî `{gpu['memory_gb']} GB`")
    else:
        st.write("‚ùå GPU –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω—ã (PyTorch)")

if sys_info['nvidia_smi']:
    st.write("**–î–µ—Ç–∞–ª–∏ —á–µ—Ä–µ–∑ nvidia-smi:**")
    for i, gpu in enumerate(sys_info['nvidia_smi']):
        st.write(f"- **GPU {i}**: `{gpu['name']}`, `{gpu['memory_mb']} MB`, –¥—Ä–∞–π–≤–µ—Ä `{gpu['driver']}`")

# --- –ë–∏–±–ª–∏–æ—Ç–µ–∫–∏ ---
st.subheader("üîπ –í–µ—Ä—Å–∏–∏ –±–∏–±–ª–∏–æ—Ç–µ–∫")
lib_df = pd.DataFrame(list(sys_info['libraries'].items()), columns=['–ë–∏–±–ª–∏–æ—Ç–µ–∫–∞', '–í–µ—Ä—Å–∏—è'])
st.dataframe(lib_df)

# --- –ö–Ω–æ–ø–∫–∞ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è ---
report_lines = []
for section, value in sys_info.items():
    if isinstance(value, list) and section in ['tf_gpu', 'nvidia_smi', 'torch_gpu']:
        report_lines.append(f"\n{section.upper()}:")
        for item in value:
            report_lines.append(f"  - {item}")
    elif isinstance(value, dict) and section == 'libraries':
        report_lines.append("\nLIBRARIES:")
        for k, v in value.items():
            report_lines.append(f"  {k}: {v}")
    else:
        report_lines.append(f"{section}: {value}")

report_text = "\n".join(report_lines)
st.download_button(
    label="üì• –°–∫–∞—á–∞—Ç—å –æ—Ç—á—ë—Ç –æ —Å–∏—Å—Ç–µ–º–µ –∫–∞–∫ TXT",
    data=report_text,
    file_name=f"system_info_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt",
    mime="text/plain"
)